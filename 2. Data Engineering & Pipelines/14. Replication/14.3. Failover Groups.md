# 14.3. Failover Groups

Canonical documentation for [14.3. Failover Groups](2. Data Engineering & Pipelines/14. Replication/14.3. Failover Groups.md). This document defines concepts, terminology, and standard usage.

## Purpose
Failover Groups exist to provide a high-level abstraction for managing the availability and disaster recovery (DR) posture of multiple related resources as a single logical unit. In complex distributed systems, failing over individual components (such as a single database or service) in isolation can lead to "split-brain" scenarios or application-tier inconsistencies. 

Failover Groups address this by orchestrating the transition of roles—from primary to secondary—across a collection of resources simultaneously. This ensures data consistency, simplifies connection management via unified endpoints, and reduces the operational complexity of disaster recovery drills and actual emergency responses.

> [!NOTE]
> This documentation is intended to be implementation-agnostic and authoritative, focusing on the architectural patterns of failover groups rather than specific cloud provider syntax.

## Scope
Clarify what is in scope and out of scope for this topic.

> [!IMPORTANT]
> **In scope:**
> * Logical grouping of disparate or related data entities for atomic failover.
> * Management of read-write and read-only listener endpoints.
> * Policy-based failover mechanisms (automatic vs. manual).
> * Synchronization states and replication lag considerations.

> [!WARNING]
> **Out of scope:**
> * Specific vendor implementations (e.g., Azure SQL Failover Groups, AWS Global Datastore).
> * Low-level networking protocols (TCP/IP, BGP) used for data transmission.
> * Local high availability (HA) within a single data center or rack (e.g., RAID or local clustering).

## Definitions
Provide precise definitions for key terms.

| Term | Definition |
|------|------------|
| **Primary Region/Site** | The geographic location or logical segment currently hosting the active, writable instances of the group. |
| **Secondary Region/Site** | The location hosting the standby instances, typically receiving replicated data from the primary. |
| **Listener Endpoint** | A stable DNS entry or IP address that automatically routes traffic to the current primary or secondary, regardless of physical location. |
| **Failover Policy** | A set of rules defining the conditions under which a failover is triggered (e.g., automatic after X minutes of downtime). |
| **Grace Period** | The duration the system waits during an outage before triggering an automatic failover to avoid "flapping." |
| **RPO (Recovery Point Objective)** | The maximum acceptable amount of data loss measured in time (e.g., 5 seconds of data). |
| **RTO (Recovery Time Objective)** | The maximum acceptable duration of downtime before the service is restored. |

## Core Concepts
Explain the fundamental ideas.

Failover Groups operate on the principle of **Atomic Role Transition**. When a failover is initiated, every member of the group undergoes a state change. If the group contains five databases, all five move from "Secondary" to "Primary" (or vice versa) to maintain relational integrity across the application suite.

### Replication Topology
Failover groups typically utilize asynchronous replication between the primary and secondary sites to minimize performance impact on the primary application. However, some high-consistency models may support synchronous replication within the group at the cost of increased latency.

### Traffic Orchestration
A critical component of a Failover Group is the **Abstraction of Connectivity**. Applications do not connect to specific server names; they connect to a "Read-Write Listener." The Failover Group management layer updates the DNS or routing table of this listener to point to whichever site is currently designated as Primary.

> [!TIP]
> Think of a Failover Group like a "Master Switch" in a power grid. Instead of moving individual wires when a transformer fails, you flip one switch that reroutes the entire neighborhood's power to a backup line, ensuring all houses (resources) stay in sync.

## Standard Model
The standard model for Failover Groups involves a **Primary-Secondary Pair** distributed across two distinct fault domains (usually geographic regions).

1.  **Steady State:** The Primary site handles all Read-Write traffic. Data is continuously replicated to the Secondary site.
2.  **Detection:** The system monitors the health of the Primary site. If the Primary becomes unreachable, the Failover Policy is evaluated.
3.  **Transition:**
    *   **Manual:** An administrator triggers the swap.
    *   **Automatic:** The system triggers the swap after the Grace Period expires.
4.  **Role Reversal:** The Secondary site is promoted to Primary. The Listener Endpoints are updated.
5.  **Re-synchronization:** Once the original Primary site recovers, it joins the group as the new Secondary and begins catching up on missed data.

## Common Patterns
*   **Geographic Redundancy:** Placing the secondary in a different region to protect against natural disasters.
*   **Read-Scale Out:** Utilizing the secondary member of the Failover Group for read-only workloads (reporting, analytics) while the primary handles transactions.
*   **Planned Maintenance:** Using the failover group to switch traffic to a secondary site to perform hardware or software upgrades on the primary without application downtime.
*   **Cascading Groups:** (Advanced) Linking multiple groups where Site A replicates to Site B, and Site B replicates to Site C.

## Anti-Patterns
*   **Partial Grouping:** Including only the database in a failover group but leaving the file storage or cache layer out, leading to "half-failed" application states.
*   **Aggressive Automatic Failover:** Setting a grace period too short (e.g., < 30 seconds), which may trigger unnecessary failovers during transient network blips (flapping).
*   **Hardcoded Connection Strings:** Using the physical server names instead of the Failover Group Listener Endpoints, which defeats the purpose of the abstraction.
*   **Ignoring Replication Lag:** Failing over to a secondary that is significantly behind the primary without acknowledging the potential for massive data loss (RPO violation).

> [!CAUTION]
> Avoid circular dependencies where Failover Group A depends on Failover Group B, while Group B simultaneously depends on Group A. This can lead to a deadlock during recovery.

## Edge Cases
*   **Split-Brain:** A scenario where both sites believe they are the Primary due to a total loss of communication between them. This is usually mitigated by a "Quorum" or "Witness" service.
*   **Gray Failure:** A situation where the Primary site is not "down" but is performing so poorly (high latency/packet loss) that it is effectively unusable, yet does not trigger automatic failover thresholds.
*   **Failback Conflicts:** When the original primary comes back online and contains data that was never replicated to the secondary before the failover. Resolving these "divergent writes" often requires manual intervention.
*   **DNS TTL Latency:** Even if the Failover Group updates the listener, client-side DNS caching may cause some application nodes to continue attempting to connect to the old Primary.

## Related Topics
*   **14.1. High Availability (HA):** Localized redundancy within a single site.
*   **14.2. Disaster Recovery (DR):** The broader strategy of which Failover Groups are a tactical part.
*   **Data Replication Protocols:** The underlying mechanisms (Log Shipping, Block Replication) that move data between group members.
*   **Traffic Management:** Global load balancing that sits above the Failover Group.

## Change Log
| Version | Date | Description |
|---------|------|-------------|
| 1.0 | 2026-02-17 | Initial AI-generated canonical documentation |