# 12.3. Lineage

Canonical documentation for [12.3. Lineage](2. Data Engineering & Pipelines/12. Governance/12.3. Lineage.md). This document defines concepts, terminology, and standard usage.

## Purpose
Lineage provides a comprehensive record of the origin, movement, and transformation of data entities across a system or ecosystem. Its primary purpose is to establish data provenance, enabling stakeholders to understand the "life story" of data from its point of inception (source) to its final consumption (sink).

By maintaining an accurate lineage, organizations can ensure data trustworthiness, facilitate regulatory compliance (such as GDPR or BCBS 239), perform impact analysis for proposed changes, and accelerate root-cause analysis when data quality issues arise.

> [!NOTE]
> This documentation is intended to be implementation-agnostic and authoritative, focusing on the structural and logical requirements of lineage rather than specific software capabilities.

## Scope
The scope of lineage covers the metadata associated with data transitions and the relationships between data objects at various levels of abstraction.

> [!IMPORTANT]
> **In scope:**
> * **Horizontal Lineage:** The flow of data across different systems and platforms.
> * **Vertical Lineage:** The relationship between different levels of abstraction (e.g., logical data models to physical tables).
> * **Granularity:** Tracking at the system, dataset, and attribute (column) levels.
> * **Transformation Logic:** Capturing the business rules and code that modify data during transit.

> [!WARNING]
> **Out of scope:**
> * **Data Orchestration:** The actual execution of jobs (though lineage may be a byproduct of orchestration).
> * **Data Profiling:** The statistical analysis of data content (though lineage informs where profiling should occur).
> * **Specific vendor implementations:** Proprietary formats or UI-specific visualizations.

## Definitions
Provide precise definitions for key terms.

| Term | Definition |
|------|------------|
| **Upstream** | Entities or processes that occur earlier in the data flow relative to the current point of reference. |
| **Downstream** | Entities or processes that consume or are derived from the current point of reference. |
| **Provenance** | The documented history of an object's custody, origin, and transformations. |
| **Transformation** | Any logic, calculation, or filtering applied to data as it moves between a source and a target. |
| **Sink** | The final destination or consumption point of a data flow (e.g., a BI dashboard or an API). |
| **Node** | A discrete entity in a lineage graph, representing either a data object or a processing step. |
| **Edge** | The directed connection between nodes representing the direction of data flow. |

## Core Concepts
Lineage is fundamentally represented as a **Directed Acyclic Graph (DAG)**. In this model, data flows in a specific direction, and ideally, the logic does not loop back on itself in a way that creates infinite recursion without state change.

### Metadata vs. Data
Lineage is a metadata-driven concept. It does not involve moving the actual data records but rather recording the "footprints" left by data as it moves. This allows for the reconstruction of the data's path without requiring access to the sensitive underlying data.

### Granularity Levels
1.  **System Level:** High-level flow between applications (e.g., CRM to Data Warehouse).
2.  **Dataset Level:** Flow between tables, files, or topics.
3.  **Attribute Level:** The most granular level, showing how specific fields (columns) are mapped and transformed.

> [!TIP]
> Think of lineage like a map of a river system. The "System Level" is the view from space showing major rivers; the "Attribute Level" is the view of individual streams and how they merge or diverge at specific points.

## Standard Model
The standard model for lineage consists of three primary components:

1.  **Entities (Nodes):** These represent the "static" states of data (Tables, Views, Files, Reports) or the "active" states (ETL Jobs, SQL Scripts, Functions).
2.  **Relationships (Edges):** These define the dependency. A relationship implies that "Entity B" depends on "Entity A."
3.  **Process Metadata:** Information attached to the edges describing *how* the transition occurred, including timestamps, user identities, and the specific version of the code used.

The model must support **Temporal Lineage**, allowing users to view the state of the data flow as it existed at a specific point in time, accounting for schema evolution and logic changes.

## Common Patterns
*   **Design-Time Lineage:** Captured from static analysis of source code, SQL scripts, and mapping documents. It shows how data *should* flow.
*   **Run-Time Lineage:** Captured during the actual execution of data pipelines. It shows how data *actually* flowed, including row counts and execution durations.
*   **Push-Based Collection:** The processing engine (e.g., a Spark job) sends lineage metadata to a central repository upon completion.
*   **Pull-Based Collection:** A central metadata crawler parses logs and system catalogs to reconstruct the lineage.

## Anti-Patterns
*   **Manual Documentation:** Relying on spreadsheets or static diagrams that quickly become out of sync with the actual environment.
*   **The "Black Box":** Capturing that data entered a process and exited it, without capturing the internal transformations.
*   **Circular Dependencies:** Designing pipelines where Table A depends on Table B, which in turn depends on Table A, making lineage tracing logically impossible.
*   **Over-Collection:** Capturing lineage for transient, intermediate temporary tables that hold no business value, leading to "metadata noise."

> [!CAUTION]
> Avoid tight coupling between the lineage collection mechanism and the data processing logic. If the lineage tool fails, it should not cause the primary data pipeline to crash.

## Edge Cases
*   **Dynamic SQL:** Code that generates queries at runtime can be difficult for static analyzers to parse, often resulting in "broken" lineage chains.
*   **Hidden Dependencies:** Data flows triggered by database triggers or manual file movements that bypass standard orchestration tools.
*   **Schema Evolution:** When a column is renamed or dropped upstream, the lineage must reflect the historical connection while flagging the current break.
*   **Cross-Environment Lineage:** Tracking data as it moves from Production to UAT or across different cloud providers, where security boundaries may prevent metadata sharing.

## Related Topics
*   **12.1. Metadata Management:** The broader discipline of managing data about data.
*   **12.4. Data Quality:** Lineage provides the context needed to investigate quality failures.
*   **13.2. Impact Analysis:** The process of using lineage to predict the consequences of a change.
*   **Data Governance:** The framework of rules and responsibilities that lineage helps enforce.

## Change Log

| Version | Date | Description |
|---------|------|-------------|
| 1.0 | 2026-02-17 | Initial AI-generated canonical documentation |