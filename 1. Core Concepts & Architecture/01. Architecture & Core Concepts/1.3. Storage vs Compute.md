# How are storage and compute distinct, and why is understanding their separation crucial?

> [!Information]
> Storage provides persistent data retention, while compute executes instructions; their independent scaling and lifecycle are fundamental to modern system design.

## Why This Matters
- **Architectural Decisions**: Informs choices between monolithic vs. distributed systems, serverless functions, container orchestration, and data warehousing solutions by clarifying where data lives and where processing occurs.
- **Cost Optimization**: Prevents over-provisioning and identifies opportunities for cost reduction by allowing independent scaling and selection of cost-optimized tiers for each resource type.
- **Performance Tuning**: Enables accurate diagnosis of bottlenecks (I/O-bound vs. CPU-bound) and targeted optimization efforts, leading to more efficient resource utilization.
- **Resilience and Disaster Recovery**: Facilitates robust strategies for data durability, backup, and recovery by separating the persistent data layer from the ephemeral processing layer.
- **Scalability Planning**: Supports independent scaling strategies for data capacity/throughput and processing power, ensuring systems can grow efficiently to meet demand.

## Key Points
- **Distinct Functions**: Compute resources (CPUs, RAM) actively process data and execute instructions, while storage resources (disks, object stores, databases) passively retain data persistently.
- **Independent Lifecycles**: Compute instances are often ephemeral, designed to be spun up and down as needed, whereas storage is designed for durability and a longer, independent lifecycle to ensure data persistence.
- **Independent Scaling**: Compute scales by adding more processing units (horizontal scaling) or increasing the power of existing units (vertical scaling); storage scales by increasing capacity, IOPS (input/output operations per second), or throughput.
- **Cost Models**: Compute costs are typically time-based (e.g., per hour, per second of usage), while storage costs are primarily capacity-based (e.g., per GB per month), often with additional charges for data access or transfer.
- **Interdependence**: Compute *accesses* data from storage to perform operations, and *writes* results back to storage. The overall system performance is often limited by the slower or less efficient of the two components.

> [!important]
> Never assume compute resources inherently include sufficient or persistent storage for application data beyond temporary scratch space.

## Mental Model
- **Data Source (Storage)** → **Processing Unit (Compute)** → **Data Destination (Storage)**
- **Input**: Raw or structured data is retrieved from a persistent storage layer (e.g., database, object store, file system).
- **Transformation**: A compute instance (e.g., virtual machine, container, serverless function) loads the data into memory, executes application logic, and performs calculations or manipulations using its CPU.
- **Output**: The transformed or new data is then written back to a persistent storage layer, or sent to another service, ensuring its durability and availability for future operations.

## Gotchas
- **Misleading Assumption of "Server"**: Assuming a "server" (a compute instance) inherently provides adequate, durable, or shared storage for all application needs, leading to data loss if the instance is terminated or replaced.
- **Silent Performance Bottlenecks**: Over-provisioning compute resources (e.g., adding more CPU/RAM) to compensate for slow storage I/O, or vice-versa, without addressing the actual bottleneck, leading to inefficient spending and suboptimal performance.
- **Ephemeral Local Storage**: Relying on local disk attached to a compute instance for critical application data, unaware that this storage is often ephemeral and will be lost when the instance is stopped, terminated, or replaced.
- **Ignoring Data Transfer Costs**: Focusing solely on compute and storage capacity costs while overlooking significant expenses associated with data transfer *between* compute and storage, especially across network boundaries or different service tiers.

> [!Tip]
> When designing a database-backed web application, you might initially deploy a single server with local storage. As user traffic grows, you'll likely separate the database onto its own dedicated storage service (e.g., a managed database service or a separate storage array) and scale the web servers (compute) independently. If users report slow page loads, you'd first determine if the web servers are CPU-bound (too many requests, complex processing) or if the database is I/O-bound (slow disk reads/writes, insufficient cache). Scaling compute (more web servers) won't fix a slow database disk, and upgrading database storage (faster IOPS) won't help if the web servers are overwhelmed.